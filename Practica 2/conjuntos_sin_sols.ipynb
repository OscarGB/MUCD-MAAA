{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Máster Universitario en Ciencia de Datos\n",
    "### Métodos Avanzados en Aprendizaje Automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos de clasificadores\n",
    "Este notebook muestrael funcionamiento básico de los conjuntos de clasificadores. Se muestras algunos ejemplos en problemas en 2D para su visualización y con problemas reales para ver sus capacidades y debilidades. Los temas que se tratan son:\n",
    "\n",
    "\n",
    "* Proceso de combinación de clasificadores base en conjuntos y cómo se modifican las fronteras de decisión \n",
    "* Tiempos de entrenamiento y de clasificación en  conjuntos de clasificadores y ver cómo varía con respecto a la creación de un único árbol\n",
    "* Errores de generalización de conjuntos de clasificadores en conjuntos de datos reales\n",
    "* Importancia de las variables de entrenamiento en el modelo.\n",
    "\n",
    "Todas las cuestiones se contestarán en este notebook directamente, que es lo que deberéis entregar.\n",
    "Las cuestiones a responder están marcadas con fondo verde y vuestras respuestas deben ir en los cuadros en amarillo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones auxiliares\n",
    "Se definen conjuntos de datos en 2D para el análisis visual de las fronteras de decisión y cómo cambian con algunos parámetros. Se definin algunas funciones (inspiradas en sklearn) que usaremos a lo largo de la práctica. \n",
    "\n",
    "La primera, *createDataSet*, es para crear los problemas, siempre con dos clases y en dos dimensiones. Sus argumentos son:\n",
    "\n",
    "- *n*, número de patrones en el problema\n",
    "\n",
    "- *model*, tipo de modelo para la frontera que separa las clases, puede ser 'linear', 'square' o 'sine'\n",
    "\n",
    "- *ymargin*, margen de separación entre las dos clases, cuanto mayor es *ymargin* más separadas están las clases, valores negativos implican solape entre las clases\n",
    "\n",
    "- *noise*, introduce un ruido gausiano a la x e y\n",
    "\n",
    "- *output_boundary*, Si vale True la función devuelve la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet(n,model,ymargin,noise=None,output_boundary=False):\n",
    "    x = np.random.rand(n,1)*2.0*np.pi\n",
    "    xbnd = np.linspace(0,2.0*np.pi,100)\n",
    "\n",
    "    if model == 'sine':\n",
    "        y = (np.random.rand(n,1) - 0.5)*2.2\n",
    "        c = y > np.sin(x)\n",
    "        ybnd = np.sin(xbnd)\n",
    "    elif model == 'linear':\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    elif model == 'square':\n",
    "        y = np.random.rand(n,1)*4.0*np.pi*np.pi\n",
    "        c = y > x*x\n",
    "        ybnd = xbnd*xbnd\n",
    "    else:\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    \n",
    "    y[c == True] = y[c == True] + ymargin\n",
    "    y[c == False] = y[c == False] - ymargin\n",
    "    \n",
    "    if noise is not None:\n",
    "        y = y + noise * np.random.randn(n,1)\n",
    "        x = x + noise * np.random.randn(n,1)\n",
    "\n",
    "    if output_boundary == True:\n",
    "        return x, y, (c*1).ravel(), xbnd, ybnd\n",
    "    else:\n",
    "        return x, y, (c*1).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función *plotModel* la usaremos para dibujar el resultado de un clasificador sobre el conjunto de datos. Sus argumentos son:\n",
    "\n",
    "- *x*, coordenada x de los puntos\n",
    "\n",
    "- *y*, coordenada y de los puntos\n",
    "\n",
    "- *c*, clase de los puntos, si se pasa None, entonces considera que x e y son la frontera real de decisión y la muestra con plot\n",
    "\n",
    "- *clf*, el clasificador\n",
    "\n",
    "- *title*, título para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotModel(x,y,clase,clf,title=\"\"):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    \n",
    "    x_min, x_max = x.min() - .2, x.max() + .2\n",
    "    y_min, y_max = y.min() - .2, y.max() + .2\n",
    "    hx = (x_max - x_min)/100.\n",
    "    hy = (y_max - y_min)/100.\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    elif hasattr(clf, \"predict_proba\"):\n",
    "        z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    else:\n",
    "        z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    z = z.reshape(xx.shape)\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    \n",
    "    plt.contourf(xx, yy, z, cmap=cm, alpha=.8)\n",
    "    plt.contour(xx, yy, z, [0.5], linewidths=[2], colors=['k'])\n",
    "\n",
    "    if clase is not None:\n",
    "        plt.scatter(x[clase==0], y[clase==0], c='#FF0000')\n",
    "        plt.scatter(x[clase==1], y[clase==1], c='#0000FF')\n",
    "    else:\n",
    "        plt.plot(x,y,'g', linewidth=3)\n",
    "        \n",
    "    plt.gca().set_xlim(xx.min(), xx.max())\n",
    "    plt.gca().set_ylim(yy.min(), yy.max())\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función, *plotData*, la usaremos para dibujar los datos. Sus argumentos son:\n",
    "\n",
    "- *x*, coordenada x de los puntos\n",
    "\n",
    "- *y*, coordenada y de los puntos\n",
    "\n",
    "- *c*, clase de los puntos\n",
    "\n",
    "- *style0*, estilo con el que pintamos los puntos de la clase 0\n",
    "\n",
    "- *style1*, estilo con el que pintamos los puntos de la clase 1\n",
    "\n",
    "- *title*, título para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(x,y,c,style0,style1,title=''):\n",
    "    plt.scatter(x[c==0],y[c==0],**style0)\n",
    "    plt.scatter(x[c==1],y[c==1],**style1)\n",
    "    plt.grid(True)\n",
    "    plt.axis([x.min()-0.2, x.max()+0.2, y.min()-0.2, y.max()+0.2])\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy6UlEQVR4nO2df4wd13Xfv4fLfa2olWPv0mVlUlyqidPCMdHYJPwDDlyxjRNZMaq0sAsLK1agfzCkqkRt4DZyFojrPzZwkwVR0bFlC7IEVbs1YWRr1LAZu7b6hNgIGlub2qEVWbFskTIpF4527cQrGSBNnv4xb7iz8+6dN3fuz3lzPsDD7r43O+/euT/Oueecey4xMwRBEARBx7bYBRAEQRDSRgSFIAiCUIkICkEQBKESERSCIAhCJSIoBEEQhEq2xy6AD3bu3Mn79u0bev+FF17AtddeG75AHpC6pInUJU2kLqNZXV19nplfrvpsLAXFvn378Pjjjw+9/9hjj+Gmm24KXyAPSF3SROqSJlKX0RDROd1nYnoSBEEQKhFBIQiCIFQigkIQBEGoRASFIAiCUIkICkEQBKESERSCIAhCJSIoBEEQhEpEUAiCIAiViKAQBEEQKhFBIQiCIFQigkIQBEGoRASFIAiCUIkIijFkeRnYtw/Yti37ubwcu0SCILQZERRjxvIycPQocO4cwJz9vP12YOdOERiCUBdRtrYigiISvjri/Dzw4ovD76+tZQIkVoeXgSe0BZWyFXPspIAIigj47IjPPqv/7MUXM0ESmjYNPBFogkrZijV2UkEERQR8dsS9e6s/rxIkvtDV9+67s8l4dTWNSblNAq0ttFHw6sZIjLGTCiIoIuCzIy4sADt26D8fJUh8oKvX2lo2GQNpTMqiSbqlrYJXN0ZijJ1UEEERAZ8dcW4OuP9+YGZm+LMdOzJBEpq69Yo9KYsm6ZYmgtd0BeJjxaJStmKNnVQQQREB3x1xbg54/nlgaQmYnQWIsp/33599psKniWDUKqdIzElZNEm3mApe0xWIrxVLrmzVHTsuSdZUx8zRXgAeBPADAN/UfE4ATgJ4GsBfAnhtnfseOHCAVfT7feX7piwtMc/OMhNlP5eWwt/DVV3ysuzYwZwNt+y1Y0ezelV9R7G+MzOb37W42L/6++ys2X1cl9H2Obhsl9jY1mV2duuzHNXGPq9vQ7vU7X++6gLgcdbN1boPQrwAvBnAaysExS0A/mQgMN4A4M/r3NenoLCdTFxNdC47i+kAdUHxOeaCYtRzjCHQYgrw2NjWxbS9iNT9kMj++nJdfCoco9B9d91x2DlBkZUN+yoExccB3Fb4+ykA14+6p09BYTOpupzoXHYW0wHqinzALC72aw3WUALNZhJJUVA0rY8rxarud4daUYRQOHRUfXfdcRhDUFD2eTyIaB+AzzLzqxWffRbAh5j5K4O/HwXwO8z8uOLaowCOAsCuXbsOnDp1aui7NjY2MDU1ZVXe1VX9ZwcOVP/vmTPAxYvD7/d6wP79ZuVwURcf5WpC3brYPPu6rK9ntu4rVzbf27Yts1NPT4/+f5ft4gKb+pjWZX0duHAh60u9HrB7d71nVvz/s2ez6TGHKLPVq+5jUrdiXWL296rvBuqVq067NGmLQ4cOrTLzQeWHOgkS6oXqFcXnAPxS4e9HARwYdc9UVxQuNfe2+SiqqFuXECsK2+9IbUVhUx+TurjoQ0tLzJOTW+8xOTnaHFlnxVKsS6wV9KjvduWjaNoWqFhRpB71dB7ADYW/9wB4LlJZAAC33GL2fpFUo2piRnmYECJscdxCZEPVx8UelPl54NKlre9dulR9j7m5bBVy5Ur2s06fjTkOq77b1Tj0sR8odUHxGQD/ljLeAOBvmfn7MQt0+rT6/fvuGx3OlnJ8dpMBF5oQAs1kEkk2lLFAqEnRhUAKJdRijsNR3+1iHHp5jrqlRogXgE8C+D6AS8hWD+8GcAzAscHnBOAjAL4D4AyAg3Xu69P0pFs61l3ipRj1FJuU6lJ32a67bmWlH6XcOmxMQibt4sIsaHoPk7HUhqinuoxql6ZtgZSjnny8YvgofEbhqEhpcrUltbrUGci6fnDyZD9sYWsQIurJlY+i7j1Mvy+1PmaD+ChaQJ1dxm21ZwsZdZb/ujZWRa3EJoRZ0ZVZ8JprNn+fmdHfQ/Jy6fFhot3urnjdIH/Y8/ObCe3KxHZOC/7Zu1fd/nmYYxeZm2s+GeXpOIqT/09+or9+3IIOXGPTFipkRdGAXENbWkrXOV2LKm9sGzy1EdE5JXfvjlOetmO6Qkg1gnBcEUFhQfSwUpvJvCqjWlvzQ3uk/KgBddubbDATNjFdIaQcQZgKTnU9nfOizS/fSQFToL+yYuc91HljJyZGe+p13sWGoRxX2yVmKEoFJs7BsepjAevSJFLHJuqpzdSpSxOHNsSZPYZcuGDnzdOpapcvV/+fanXRdAWSqzyrq8DOncC73rXlHstHvoR9OzeiW7/EceqfJiuENuz9iYXrPiuCoq3owmvqevNsjLnlHtf0hJpcuADZcXeFOi3jNhy99Ec4tzYV3fqVquN0nNxI0c24LUbVD1z3WREUbUUXXlNXAJicJqSi2OOa9EqVcCl+jN/Hi7h2y3uxtPi6jtPl5SzpW4iJexzdSLJCMEfXD3S+sqb6oQiKtrJ7t503r6zCTUyYfX+xxzUJQRmh2jwL9f/G0OLrmEXyAXvxYpiJu43msHFaAeXErpOuHwBunf0iKNrK9LT9Wr2owh09mt2nyI4dwPHjo3tcEwPzCNVmL9QSIUb4Yx2zSOiJO1VzmA7XK6DYE3ReBterOtN66dp7fd2xKU/n5W7zqxNRTy7rogqRIGI+fnzz81HhJaYRS4Xv7C8uZt85OZmdkUrESzO/yTt6l6xSQoQkzwFWPNbVZ+rqECnXUz1FsUlEj4+x77oNmqQZd1kGSK6nDBEUGmKchcp8Vbj0FxeVwiXRaFkl+SMsCwpfjzDEGSKpnqLYpLv6GPuuz7VochSqy35QJSjE9CTEs2Pkpq8DB5TeS9/OTZfmi9AbwNoWJeRyJ3UqZjfXu8Ob1CtUPxBBIXQyH4Jr+3I+YHu9cBN3m6KEXArSVLqra+Wgab1C9AMRFEJ1j0/Ba+gBH87nubnsbOM2TNyhcan5ppK+w7U2n0q9VIigEPQ9HgCOHNmqdh85siksWixEUjFfdAlXmm9KZjeX2nxK9SojacaFDFVe4p071YcY33139nsxL3Ruu8nvlTi6NOFjbG0bK1yn0daxvJytMp99NusbCwv+zYkpDh9ZUUQkeYV8bU3/fsiNAx4eVMrLfNck388SZRx3vzdFBEUklJ3w9hewvPO32tETQ9luPI3WlJf5LunqZFcWjuvr5vdo4+53X4igiISyE+JazK/9djojeWZG/36o0JO6o7WB2tymqKEiJlUNMdmltmJRCcdz58zLJX6sTURQRELbCbE3HbXl3nuHkw/2etn7TW03rnIUFN8fY7W5/LjuvNOsqr4nuxQfvUo4XrliPqRSCcNNAt1OvDa/2rAzW7sLE8/U2t4ZrC5V26NNU3vMzDD3ekPbSPsrK/p7zsyM3q7acGe5j53fLttFl1nFpKo2m+7r1CXWpv4qVM9ocbFvvGM6xO73Jvga+5AUHhkpCQplJ8QGL+G2WiMtpbpoUVVS8eqfPKm/fnJSKVy2jNYGuRR8TQIh8iOZVNWmnnXq4jqNhQtUz21xsd84r1RqaWRiCAoxPYVmYEuYO7wN91/zW5idWgPhCmZxFvfjvZjDJ8cn/GbEmRNXyQ8sUl1/6RJw3XXVXucGNoI2OCpNzEO6qvp22qdonlFZRbdtazak2urHco0IipCUDLpzax/G2St7ceX4XTg7exPm6NR4hd/UnelyP0hVzuSq0drAX9IGR6VuslVlg491ZGiKYcYq4Tg7Ox5DKhYiKEKiU2NPnx5PtaWOWrljR3YIU9X1uuO6chqozSlqwmV0k/CxY+HCekfFHqQaZlwWjqO6UOoU2+HMmfDBAiIoPLNloJ17DMu4bfiiJmrs+npaMYkqVDPd5GQWXlucVfJRvLCQfV7mxz8eXT9DtfmWW8w189DoJuGPfjSMXrG+Xi+iScwzfilHll28GCGyTOe8aPOrrjPbt6NqpMO6aYjI0hL3T5xw74n1QY2HvKVd6kQ5OShS1TlNNugcjSk6RUdx8mQ/uYimprQi+END2Tmfn3niuh0gzuxhQsR/azfV4fc332iixs7PZ+rblhsn5onNMVU3dVtoHToPVO3CnFkAddhsKnPV10JvbMtjDMqk5MfR4WJndiqk4E/rrKAIEfVSuanOxqCbQs/xRQDngenjs53oXfS1GBvbynstc1Ly46hwtTM7NDpFIAV/WmcFRYi5VtvAs9vsDLop9BxfBAijMX18thO9i74WI5x39+70Iprq4GpndkiqFIEUIss6KyhCzLXeGnhhIVM7ihBlvStVx3ZdAoTRmLaL7UTvoq+FSMVR1manp9OMaBpFGxfcVYpAeUj0ehHaQee8aPOrjjM71PZ8X07M/srKppervD02Vce2hhiORpN2MUlToaqLi77mM1WGrnwrK8N1aQMud2aHwmSHe+d2ZhPRzUT0FBE9TUT3KD6/iYj+loi+Pnj9nqvvDhX/7S10cHo6u+HsbNaniqTq2E4Ik3axXRm66Gs+zQ86bfbCBft7x8DlzuxQpG5NjnbCHRFNAPgIgLcAOA/ga0T0GWb+q9KlX2bmt/koQ6qnSRnRxnV2y8j7iM1JZ7Z9zUUZdOi6ii7qKXXyZ3L33Ztnb5UttamxsLD1wEggLX9QzKNQXwfgaWb+LgAQ0SkAtwIoCwqhCjnTMwgpKBW+yqDrQrqop7bwk59s/v7Tn6Z9Uq9PRcAFxGWzRagvJno7gJuZ+T2Dvw8DeD0z31W45iYAK8hWHM8BeB8zP6G531EARwFg165dB06dOjV0zcbGBqamppzVYX09W55fvJgNqt27PacKKHzhxg03YGr7QM6fO7d1X8W2bZl9oyV5C1y3S0zaWJf1dXUXuvHGDbz0pVNXrwna1y05c2brimjPng2cPz+FXg/Yvz9euVzgq48dOnRolZkPKj/UOS98vwC8A8ADhb8PA/hw6ZqXAJga/H4LgG/XuXeINOPBc9WXvrC/uLj5hW3c9lugzbtmy6RWl7pdQ3VdXpdUz2Woouwcznczx0x/7oquObPPA7ih8PceZKuGqzDz3zHzxuD30wAmiWhnuCLqCR7XPip+TpLt6Am8pTmVo0FNNunputDyMnDHHemnZC+TunPYBz77XUxB8TUArySiG4moB+CdAD5TvICI/iFRlrqNiF6HrLxrwUuqILgPWZzWzQi8pbluIr0Q2CozeV0uX1Z/nvJu5xQ2qYXEdzePJiiY+acA7gLwBQBPAvgUMz9BRMeI6NjgsrcD+CYRfQPASQDvHCyRohNcY+miiuSCwEu/CxfcpOtwoRna6haqupSJfT62Dleb1FJZHY7CdzePGjTGzKeZ+eeZ+WeZeWHw3seY+WOD3/+ImX+Bmf8pM7+Bmf8sZnmLBNdYuqYiuSLwSsw2kZ5LzdBWt6gTHpuKCUo1oRfNafv3NxMSqawOR+G7myceXZwuwQ9sSWIffwsJvBKzTaTnUjO01S3qhseaCEEf2rmvCb0Nx+Xm+O7mIigsCO5DtlWRukjglZhtIj2XmqGtMqOqi4o6k5FP7dzXhN4mt6Dvbi6CoiZtsVUmScyHF3jpZ5tIz7VmaKPMlOsyMzO8yqg7GVVN5rbdw9eE3ia3oPduroubbfPL9T6KFOPIU4vX11Lj4VnXJaF9JLZ1Samv6RIcNnnUuqR3ef18J0xs0i4ptUWRru2jaA1tslUmh++H1yaPYw2C+74MabpC0WnhExP23cOX2SX1tgiJCIoaGC1tx81G5dMukN97dbX5sxpDKT6O+yd1k7luj4aJ2cjnhD6ObdEEERQ1qG2rHDPt1kl9dA9venrz3kDzZ9Umj2OH0U3ms7Pq6039ADKh+0UERQW5wnvuXNa5iyiXtibabRtWHi60dZ0qmd/L5t5Ac49jG57/mKGazFXdY3IS2NiQpkkJERQaiso0kCnUubDQLm3rareprzyKElKFC7vA+rr9vYFmBurlZeDIka3P/8iRdJ5/hyh3j5mZ7OfaWppDo6uIoNCgUqaZsw6tXdrW1W5TtquXJaQKF3aBqmdlou3XMVCX7/cbvwFcurT1PpcuZSfdCMEpdo+pqeEd4akMjS4jgkJDI9N3Xe02Zbu6SogVcbWLZ2FhOCi/1wN+7ueAw4fNVltVBmrV6u2FF9T3WUsi32SnSXlodBkRFBoamb7rhl+kvJOnakS6jg8s53e8fBl49FG3Z4CPEnxCLVy6dKrulfLQ6DIiKDQ0js2uE36RcoI/3YistLk1YH5+2Pyji5UEmquUJv83M9PsO8Ycly61UfdKeWh0GREUGrxutkl5J0+okWo68TdVKev+X68H3Htvs++oYByCq1y61EbdK+Wh0WVEUFTgNTY71cDvUCPVZOInai6odILv+PGtdXzwQed1TD24rS4u/QZ17jXK5bRvX9Zs27dnP9sqgNuECAphmBBCTDWB93pZEH0RIuDYseoopnyW0B1KoBJ8H/2o9zqO0p5drTZ8rVrW17P76Y4Ka7LIs/FBlAPycktlWwVwq9AlgWrzy3VSwBQZi7oMMsz1Fxc3M8yNyjqny9R2/HgSGdyK7aJLgkfkLuGcr8R1S0vMJ070KxP5NfkOm/Lqkv+pkgCWGYvxMiBGUsDok7qPlwiKdmFUF91sMTFhPnt4IK/L0pI+Y+rsbL2Mp3VwdR/VfRcX1YLCNkGvjwy0uQDW0dnxYkCVoBDTk5A2ZbuKbiOgi+xyDpmfV5tscneLK7u/r30Huv8niudSG2WekhBaf4igENJF5Q0uJ93KmZhQvx9p9tBNtMyjN6ab4Gvfga/72jj4VW6tHNeBeeMQreYSERRCuujyqKgyNB492iznk6fZoGo7CuAuCtlXNPPCQvZYXN/XJtS2GJcAbOoGrgPzxiVazSk6m1SbX+KjaBfaulQZpVVGbhPjtycvcNFHMer2rg7m83XA38pK3/l9dU1a5V9wgcl48eX3cUUMH8X22IJKELTs3av2SeS7xMvMzdVXK6tUWweqaX6L+fnMDLV3b6aNF29tUtxR3+XDZzA9rX7MNuiaNCX/guSbGkZMT0K66IzSGxv2doAAs0Gqeypj0oYUHZJvaphuC4pQmc6EZuRG6XIOprU1e6OxzAZRSD1Fx/JypoeUSU2Yhaa7giJkpjOhOXNz2SEFZWwPKWiDajumpLrSyodxOdv8zExawiwG3RUUITOdhWCcVzQ+zEQRVNuYTeT7u8eh++ky0k9NdVtIAOiwM9vF5LO8nPUuF0eG2pCrQnkvz1c0wHj0cF8eUF9eYAUxm8j3d49L9xMntp7urihsbdQ+jgxtSgorGp+MgZkoZhP5/u5x6X7ittLTXUFhO/mEOjK0iny972NFk5ItwaeZyHU985SrpfvZaqs2xfStKY+LJj4G+og/dBss2vyqveHOZqfSqM1gnrOW9ldWhnd0udoh5CslqYZomwdd13NpifsnTijvZ7OJy7aYTb+7brukvkGNuX5dfG1edEmxLi7LC8kem+F0Qoo8OvonT1YLCZsJL3DdogkK1/XMU6Yr7ucjvXbdYjb9bpPJNYEM75WMYyYD18+9SlB01/RkS+x16sWL+s9MTDMqm4YrR38qpisdrm0mFfezsZ7ZFtN3gFfqeyPGlaC+IZ0ECfECcDOApwA8DeAexecE4OTg878E8No69w2W68n3OrXi/toVhYk2rFNJZmaCqrBdWFGkVMy6jKMWPg7kdXGdNwtNVhREdJqI9nmQTfn9JwB8BMBbAbwKwG1E9KrSZW8F8MrB6yiA+3yVpxE+dw6N2sS3e7f9ikankuT3anrvtoTBuF4Vekq5GnvxmgptWKTaYFq/oFFaOgkC4N8A+GsA8wAmddc1fQF4I4AvFP5+P4D3l675OIDbCn8/BeD6Ufcei+yxI9TIfr9vv6KpUkl8OPo1qk7UdnG8KuyvrHhZZcZwsqY0Xmzt8SnVRYVJ/WL4KCj7XA0RXQvg95CZiB4BcKUgYE7YCCgiejuAm5n5PYO/DwN4PTPfVbjmswA+xMxfGfz9KIDfYebHFfc7imzVgV27dh04derU0HdubGxgSpUOAsjCGi9cyGz/vV6msU9P21TRjtVV/WcHDlTXpS5nzqh9Hb0esH9/sPs6qUsiSF38YNtVU6qLCpP6Fevicto6dOjQKjMfVH6okyADAdJDJii+BeCDAD6Qv6r+r84LwDsAPFD4+zCAD5eu+RyAXyr8/SiAA6PubbyiSDFso86KgtlO1fRV77b4KDwgdfGDrT0+pbqoMKlfUmdmE9HNAL4OYAcyJ/IHmPmD+auZzNrCeQA3FP7eA+C5BtfYk6JNvY5h2jYZoa9wlRBhMONusEYnqlgbn0ezhnjGy8vAzp3ZcCDKfi9+V/K7wnUSBMCXAfyC7nPbF7I8U98FcCOylcs3yt8H4NcA/Amy6Kc3APhqnXsbryhiHbs1iqqop34/+l4OV1Su9HQn2aW2AhzgSttLoYopaeE+fBSj7unyBMJeb3iYTk4269IxVhRehEDdF4BbkDnMvwNgfvDeMQDHBr8Tssio7wA4A+BgnfsaC4oWTrj9fj9dAWeIsl2qRo7P9rKcHVw5s1PokikJCma7plHVpeoZuxTUuu8pt2fd+nVOUPh6jYWPYgStWlGUR8Dx41v+7q+sDP9PVd18CUjbflCRwsOUqgwxobpleby0Ib2FDtXYr+pGLodWVVuquuyo5yyCIpagYG7dKLgaHpu6gFOVsfTqnzgxXOZQo7iI7X0dbrir0kJdNnGx28/MZK/8Ea+s9Ldcl3pXq8JkRZE/A1e6SN0VBXO95yyCIqagaBlOop5CUDVKckGxuJiNzjr/59ouUMR2diBSC4oGs8so+erKylb1HSdO9K8+0rYsXnXofBQ634FtcoK631PusnWec1JRT4IFIcNVUj1XMqduQqK1ta3PqSrqy1dUlW3oSYP/13WVvIo6XKTwHpUp/8qVzcC/cUklXmRuDrjuuuH3L13Kftrshi+26/w88O53bz36fWYGeOih4S6re57nzm32kfX1emVwik6CtPkVdUURaI0+si6xVxpVTmfVikK3Dg9Zh8A+ijpf51OTr7KdA8yLi/2ri6FxXFEw+0lO4CNTsG6l5xKI6SkjiKAINKJG+ltiGpRr+CWUgiKFaK2AUU91uorPphw1KS0u9q+WJXaXakKxKU+eVE+uPoarzT3rDJ1iu7hEBMWAIIIiUMhqZV1Cqn+qibXmSmLkiqKFbGmXEUKnblfxtbBaWqpeVZQ119iLVBPKE+7iYl8p2HwIQNspoPicR630XCKCYoCVoKg7SlJYUYTaX6EbZQZC4qqgMB2dic5aW4IMRsxAKZhzjh9Xd5eZma1RT22j/GwXF/vaZ+u6K7lsV9W9ZEWRqqAwUTtS8FGEmoF03zMxUU9ITExkkUInT6aRo8oBV9ulRhukUg3dRFlnvCQqr4eEXy4oQlg3Xbar6l7io0hVUJhOvAFGTxI+iiq7xaiVRaE8xu2Sgiqu4Wpdaq7qUp1omUe3i89uZvtcTFYUPnDZruV7+VrpiaAY0HjvQYKpMpKIehq116FiN3axPMaCIsH2yLlaF10gfnm/SMKMahdX8lrVVWwFUF0fRRuJsY9ie4SI3LjkGVfzAPI84yqgj8Pfuze7TvV+qszN+d9TsbCw9VkCwOQksLEBHD6cPZ9HHnFfjja2xxji6mj18nC8T3GOZZ7MuW5Xyq+bn8/K0+vJOd42dG/DXZOU4iZnUXYpN3R549vMTPZzbS1T5EzTntclxbNB83ZfXc1+rq2pr4uyW8oPLlJjj9r0V0SlG1RR3Iu6f78ICRu6JyiaqEF1dwLbng/RRoqjcWpq+JguH+d6hDjvwoRiuwPZTyL1tWO06nEhr01WHxMT9a/1RZf0wCLdExRN1aA6qTJSPAApJCHyPOQj9fDh7O9HHomfukTV7szDwiL2qscxLuS1idy8fNm8jC7poh6Y0z1B4dNsUTVRdkEV8X1MV6ojVdfuzOmsejxhm2pMNRx1zM6als4tsfXAsnUzZLfvnqDwabbQTYjT02lOcK7x7TuIPVJ16Np9dtZpwsZx1DVUbi6VianXi78Yi5kYUWXdDDmFdE9QAM3UoDqjVDdRAmlOcK7x7TtINYVpAOd6qospFxSH4/PPAw8/PJxp9cEH4y/GQiyYdVNMdB1JFzfb5lf0ndnl/QIe4v6t6pLYDq/adUl4o13+XPuLi16ea4yqp3h+S9Pu66IuvjcYau+9tMSEy0ObB11vHYJsuMsItjPb9f8raFSXVHJGlKhdF1ViogTKX8TX5Bpjj2FqgsKm+7pKR+JLz9JOETM/Zt6xg2fxjFJQuFQUqgRFN01PptiaPFKJ+4++frVgeTmzSTBvvkcE3HFHfJtEAHybPdqArvvefru9z6auac/XOWHaKWZtB/Dii1jA72IHXtjyWcgpRARFHWxHaSpx/6nZ+E3COHQhqKdP+yxhMqSia8SkqpvqJva6XSy2DqWdYpBVeg6fxP14L2ZxFgAwi7NBpxARFHVwMUpTOLI0JbXUNIwjNSFni2EIUyq6RkxGddPyxG7SxWJ3L+0UM3Pi6t9z+CTO4kYcwCrOzt4UtO1FUNRhXEZpSmqpqQqXkpCzpWEIUwq6Rkzq7LkoTuwmXSx299JOMfe+frjS27YFH7MiKOoyDqM0JYFnqsKlJORsiW3naCnF7qujOLGbdLEUupdyilGN2dnZ4GNWBEXXSEXgmapwKQk5W2LbORKhyQbCvPsuLY2e2E26WNLdqzxmp6eDF0EEheAf1YzQRIVLRcjZEtvOkQC2GwjrTOymXcxF9xrH3fOACArBN7oZAdhqR0hKhfNMCnaOyLiwvo2a2MumKt9dbJx3z4ugEPxSNSPkI/3AgbRWCL7VwqTtHGEIZX0L2cXG2fXUvRPuhLC0zR7f5ATEJoQ4gTBhxvGQwrZ1dRNkRWGKSttsk2EydFnbZo8fZ7UwIWJa33wNgbZ1dRNEUJhw553ZgTlFI+S73gUcOdIOw2QMI2rb7PHjrBYOcDFR2t4jlvXN5xBoW1c3QpcEqs0v50kBmauzwEbIaNqoLrGyr47IpJZU8jnLZ5RUXRSYJNbT1cU0OV8KCYvzuvgeAiHq6quPQbLHZlg9YF0P0718pvXkhnWJkYK0BrXrEmIUNk1R6jnNuCtMJkpdu5jcw3fC4rpdIq9LkyHgutvZ3q8zggLANIAvAvj24OfLNNedBXAGwNerKlF+eREUJquJtq0oJiaiqnu16hIyRbrpSC6Urb+46KdsjmYrk4lS1y5V3b6MTw2+yerItDyuu52L+3VJUPwBgHsGv98D4L9orjsLYKfp/YOvKCYnw0xgBZydR1F+RTjfoVZdUj60qFC2q4LCtT3D0WzlYkUxMaHXN8r4XMQ2qYvpo3Td7Wrfr0IxiCEoYjmzbwXw8OD3hwH8eqRy1EflqSICjh8HHnqoHTHxZQ+i6nDiVCN8UnYy+y6bw0gsFw7Xy5frv+8zEqjJYzd1ortu2lr3S3DnHmWCJPCXEv2ImV9a+PuHzPwyxXXPAPghAAbwcWa+v+KeRwEcBYBdu3YdOHXq1NA1GxsbmJqaal7w9XXgwgXg4sXstPfdu6PkXQEc1AXIkvTrOHDA7t4G1KrLmTPZcy/T6wH797svlElbF8q2sWcPps6fd1s2x+1Ut2q6djFpivX1bJ67cmXzvW3bsgnaduiYlKPpeHHd7Wrdb8RFTsa+gkOHDq0y80Hlh7qlhu0LwJcAfFPxuhXAj0rX/lBzj1cMfv4DAN8A8OY63+3F9JQYTuqSiDknSR+FaViPTx9Fw3by5TRNJerJRQSXy++odb/jX+Yd2Nh6P2zw0vEvb140wl7XJR/FUwCuH/x+PYCnavzPfwbwvjr3F0FRk0TO0E4q6om52cTsM+qpQTtV/YtppJDu/rFDXk3KYTNenNZ1dpaXcBvP4hkmXOZZPMNLuG1r3xrR/7okKP4QW53Zf6C45loA1xV+/zMAN9e5/1gIilB7DxIY8cm1i4UH1ltdDNtJN9fMzPjXwlMkmbrU6VsjFIMuObM/BOAtRPRtAG8Z/A0iegUR5Ycg7wLwFSL6BoCvAvgcM38+SmlDE9KZFSt1d3Fr75kzdnVznZMhxVwMhu2kc5qurUmGkqjU6VtVHvfl5Wy8hE4XpJMgbX61fkVRw/TRmrqoKGlM/cXF5iYvH+azUfeMELpoiov9oanUxQXJ1MWmvw7+d0sItkNTMRJcUQhVpBwK6gKXifd8JPEbpdHFDl2ssYLShcHOzKhvOQ6J61qBTZKriAkrRVCkSIqmDxvKE5sqvzSQCUJTM5Ivoaoz9cTOLltTUOnmo3vvHePEdW2hqbk3ogIpgiJF2pyGsjzR33nn8MRGpP7f6WlzbT20UI292jMQVKr5SM5MajERFUgRFCnS1tGs0nY/9rHhiY15WFjkgtFUWw8tVGOv9hwIqnE5enwsMFlBR1QgRVCkShtHs0rbZVZfy7wpCLdvB665JgvJUeEyJ4MtsVd7sQVVgTad1+USZ/U29Xflfb3XC69A6rzcbX61PuqpBknWpcl5HUtL3D9xot61qRAz6ingJslRG+5C7tVMJTW3db2LFdFlVxzR37u0j0IYR3RarcrMlGvg8/NbEwGVie2bUamPMVd7iZglQ/r0Uwg0y7Gqd7kiuuyKCUY3iqAo0tW1tCt0Zpljx/QTW9WgqJoEQ7RVSjNUkVGCyvGzUd0upE8/dqBZEat6qyqioqhwpTIn6ZYabX4ZmZ7ypWC+6yhy3qO6JGl6Yja3EeT5kUzzKoWwezTI+RS9XRw+m36/r73dzEw4K6GLMy1ctYtVHs06ptnyxk7Fw++vrDipSxmI6UlDUWMEhh2vktvAHFOzzMJCpi0VGWVuCqVixg6FbYLjZ6O7HRDOp+/Kf+9CObeKZdAVeGJCvdrWPfwLF4zLbUu3BUWdpWDKk8I4MDeXDRATm3uoCTyhCKPa6J7BuXPGs2R+loTus1CuEheBZuvrbqyIVi4iXUUeflitWOnaUnVWhWe6LSjqTCwpTwrjwvS02Sok1AQeOxS2CVUBBQaz5PKyXkjkXxPKp+/Cf3/hgruFVuN6m1ZE15a9nnmhLem2oBg1sdhMCqk4ocaRhYXhwdLruZ/AY0QY2fYb3ZG9hmbVqmC0GLLSVijplPDgBgOTiugUlZ/5meBzS7cFhW5QAXaTQqrRMuNEeeIr/+2KkKGwLvqNSrjpnk3FLFk1gbYhSUAZnRKetMFA1ZZ33JFtTA08t3RbUKga4pFHsgawmRRSiucbR+bngUuXtr536VL7n6+rflMWbrOz6usqZkndR7OzcYVE0wXX7t3tsyICGG7L06eHl3oB5pZuCwqgucZY1WPbGC3TJsb1+fqqVwNfS5NgNN/YLLimp5PYp2hPpL4vgqIJo3psG6Nl2sS4Pl9f9Wrga2kSjOYb2wWXNytiSH9kpL4vgqIuxc5wxx3VPTZ0tIzLjtoGJ3wbo5HqcMst1elOypi0VYNZ0jQYzTdJLiRD+yNVSz2irO/4RLcTr82v2juz6+4iVu2QHLVV1DaL2Qiu1sXlLuXQmd4GNNo16/n5NqXxDmDVsydiPn68/vWO2yr6LvMSNruivdXFaqt2M/oPP+wliwQqdmZHn9R9vGoJCpOBVvcA4oBZTq/WxWVHjdDpmdObkGxoXBfTZx+grVJrFxvZ6K0uLvKLGNI/edJL21cJiu6ankwMnnXWtrFMHy7X40mu7TuC6bMf07aqsqaZulqK9zpzxpM1KIbPIMKmkO4KCpOBZpqjJSQuO+q4OonbgOmzT7itmrq56pj767payve6eNGT6yCGP1KHx7bvrqCYnq7/vmmOFhN87MRt2lHH1UlsQyjnvumzD9lWBs/AxrfrcvtRsK1MIXbv58+fCDh8WH2N73Gqs0m1+VXLR6HLkzwzozbg+XCeWhhdh/wtrsoWwUmcmi38Kg3ax6oux49vnno2MaF3ZBfL5ztgwvAZ2LhOXJr7y/daXOz7dh34QfH8h9LyT0xsbY+G/QLizM7YMogjOKGGsBhVyU6uDUi2LiHPo4gUcVZFv983fgY2w8pnXEYuKFI7VXckiocyJCjK0ZYN+1GVoOiu6SkFG++YOiTHhq4c4+Ywy4DNsBIrqgLTDNee+lF3BYVug4rvjStFUhBWgp6Q7RNLaXCcZcBmgnZp7i/fq9eLv7O8EaYZrj31o+4KitOnzd73wdioPWNKyPYJrTTkq4jbb3eaZcB2sneZZqN4r/37WygkAPXzz1E9XE/9qLuCIgWzT4zzDoT6hGyf0FFMxSOAVeTjoGGeqJRSf7SW5eVNU9LERPbe7Cxw443Z6k/1cD31o+4KilTMPjajqg15mdqOqn18PPeQQqnOEcDFcSAzf3jKwvzy5c0JXxfaD3jrR90VFG03+7g6BFgww2cSuFAT8qhVc5vGgStSU7psnNIe+lF3BUXbzT4uDwEW6jMOh1JVrZrbNg5c4EL4uxY0KZjGC3RXUABbJe/CQjbYdQ2dmsaRzCHAA1J7Pr5IbAA3QreaXlrqpmnJVvj7WGWmYhofEEVQENE7iOgJIrpCRAcrrruZiJ4ioqeJ6B5vBRrV0CmegZ3SIcApPh9fJDaAG9H21bRrbIW/j1VmYqbxWCuKbwL41wD+VHcBEU0A+AiAtwJ4FYDbiOhVXkozqqFTNDekdAhwis/HF4kN4MbEclCnuPK0Ff46gXLuXPO6JibMowgKZn6SmZ8acdnrADzNzN9l5osATgG41UuBRmkUKZobUjoEOMXn44vEBjCANCdfFamuPG2Fv06gENnVNaFoM8pSfET6cqLHALyPmR9XfPZ2ADcz83sGfx8G8Hpmvktzr6MAjgLArl27Dpw6dWromo2NDUxNTQ3/85kzapt/r5ft1Bn1eQS0dYmB5fNJqi6WBK/L+no2CV25svnetm2ZAKsKo6yB87pEHEcj67K+ngWIXLyYlWf37vrPT9UGVZjev4SvPnbo0KFVZla7AnRJoGxfAL6EzMRUft1auOYxAAc1//8OAA8U/j4M4MN1vrv2Uah1E2mlmrAtFUyfTym7ZX9lJWhxfRK8XTyedOe8LhETcXpvl3LGVlU9i69eL8tU3SDzr6+6IEZSQGb+ZWZ+teL1P2ve4jyAGwp/7wHwnPuSYrQ5IUVzQ0qYPB+V+eHcufjmh7bSJrPfOAQC6CibiWZnq6+/eBFYW0vLBFdByuGxXwPwSiK6kYh6AN4J4DPevm2UPTAhe2GS1H0+Ksf3lSvj6fgOQZsm39QCAXz6dqpyNKlIPPgjVnjsvyKi8wDeCOBzRPSFwfuvIKLTAMDMPwVwF4AvAHgSwKeY+YkY5Y1GW5yUJrRJA24DqU2+VaS0MvftWC/WtS4Jj4FYUU+fZuY9zPz3mHkXM//q4P3nmPmWwnWnmfnnmflnmTnBnu+B8rGHqUWI2NImDbgNpDT51iGVlXmTkG5TxS2v69JSvdVFwmMgZdNT9ygnAitHpCW+PK2FSgPeti1NDbgtpDL5tgnTla3NCqQszGdmgMnJrdekugocIIIiJepk9Ux4eVoLlQY8OyuTmxAW05Wt7abSojB//nngoYfaswqECIq0MD32sK2UNWDLeH9BMMbUt+Pat9ayVaAIipQwPfZQEIRmmPp2Ou5bE0GREiothyj72YLlqSC0ChOtvk3RZR4QQZESKi3nkUf0xx4KghCGtkWXOWZ77AIIJebmOtP5BKFVdHhsyopCEARBqEQEhSAIglCJCApBEAShEhEUgiAIQiUiKARBEIRKRFAIgiAIlYigEARBECoRQSEIgiBUIoJCEARBqEQEhSAIglCJCApBEAShEhEUgiAIQiXE5eM2xwAi+hsA5xQf7QTwfODi+ELqkiZSlzSRuoxmlplfrvpgLAWFDiJ6nJkPxi6HC6QuaSJ1SROpix1iehIEQRAqEUEhCIIgVNI1QXF/7AI4ROqSJlKXNJG6WNApH4UgCIJgTtdWFIIgCIIhIigEQRCESjohKIjoZiJ6ioieJqJ7YpfHBiJ6kIh+QETfjF0WG4joBiLqE9GTRPQEEd0du0xNIaK/T0RfJaJvDOrywdhlsoWIJojo/xLRZ2OXxQYiOktEZ4jo60T0eOzy2EBELyWiPyaibw3GzRuDffe4+yiIaALAXwN4C4DzAL4G4DZm/quoBWsIEb0ZwAaA/8bMr45dnqYQ0fUArmfmvyCi6wCsAvj1NrYLERGAa5l5g4gmAXwFwN3M/H8iF60xRPTbAA4CeAkzvy12eZpCRGcBHGTm1m+2I6KHAXyZmR8goh6AHcz8oxDf3YUVxesAPM3M32XmiwBOAbg1cpkaw8x/CmA9djlsYebvM/NfDH7/MYAnAeyOW6pmcMbG4M/Jwau1GhgR7QHwawAeiF0WIYOIXgLgzQA+AQDMfDGUkAC6ISh2A/he4e/zaOmENK4Q0T4ArwHw55GL0piBqebrAH4A4IvM3Nq6APivAP4TgCuRy+ECBvC/iGiViI7GLowF/wjA3wB4aGASfICIrg315V0QFKR4r7Xa3rhBRFMAVgD8e2b+u9jlaQozX2bmXwSwB8DriKiVZkEiehuAHzDzauyyOOJNzPxaAG8F8O8Gpts2sh3AawHcx8yvAfACgGD+1i4IivMAbij8vQfAc5HKIhQY2PNXACwz8/+IXR4XDMwBjwG4OW5JGvMmAP9yYNs/BeCfE9FS3CI1h5mfG/z8AYBPIzNFt5HzAM4XVqp/jExwBKELguJrAF5JRDcOHEDvBPCZyGXqPAMH8CcAPMnMJ2KXxwYiejkRvXTw+zUAfhnAt6IWqiHM/H5m3sPM+5CNlf/NzLdHLlYjiOjaQaAEBmaaXwHQymhBZv5/AL5HRP948Na/ABAs8GN7qC+KBTP/lIjuAvAFABMAHmTmJyIXqzFE9EkANwHYSUTnAXyAmT8Rt1SNeBOAwwDODGz7APC7zHw6XpEacz2AhwcRdtsAfIqZWx1WOibsAvDpTCfBdgD/nZk/H7dIVvwmgOWBwvtdAEdCffHYh8cKgiAIdnTB9CQIgiBYIIJCEARBqEQEhSAIglCJCApBEAShEhEUgiAIQiUiKATBM4NMuc8Q0fTg75cN/p6NXTZBqIMICkHwDDN/D8B9AD40eOtDAO5n5nPxSiUI9ZF9FIIQgEG6klUADwJ4L4DXDLIZC0LyjP3ObEFIAWa+RET/EcDnAfyKCAmhTYjpSRDC8VYA3wfQysyyQncRQSEIASCiX0R2yuIbAPyHwQl/gtAKRFAIgmcGmXLvQ3bmxrMA/hDAYtxSCUJ9RFAIgn/eC+BZZv7i4O+PAvgnRPTPIpZJEGojUU+CIAhCJbKiEARBECoRQSEIgiBUIoJCEARBqEQEhSAIglCJCApBEAShEhEUgiAIQiUiKARBEIRK/j8t04M6VBJPTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Problem data:\n",
    "np.random.seed(11)\n",
    "n = 300\n",
    "model = 'sine'\n",
    "ymargin = 0.\n",
    "noise = 0.0             # <========= Modifica este valor 0 ó 0.3, (antes responde a las cuestiones de arriba)\n",
    "x1, x2, ytrain, xbnd, ybnd = createDataSet(n, model, ymargin, noise, True)\n",
    "x1test, x2test, ytest = createDataSet(n*10, model, ymargin, noise)\n",
    "plotData(x1,x2,ytrain,{'c':'#FF0000'},{'c':'#0000FF'})\n",
    "Xtrain = np.concatenate((x1, x2), axis = 1)\n",
    "Xtest = np.concatenate((x1test, x2test), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Condorcet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_error = 0.6  # <-- Modifica esta probabilidad para ver cómo evoluciona \n",
    "                  #     la probabilidad de equivocarse del jurado\n",
    "num_jueces = 31   # Mejor que sea impar para evitar empates\n",
    "\n",
    "p_error_jurado = np.zeros(num_jueces)\n",
    "for i in range(1,num_jueces+1,2):\n",
    "    mayoria = 1 + i//2\n",
    "    p_error_jurado[i-1] = np.sum(sp.stats.binom.pmf(range(mayoria,i+1), i, prob_error))\n",
    "\n",
    "# Puedes cambiar a semilogy para ver mejor cómo baja la prob de error\n",
    "plt.plot(range(1,num_jueces+1,2),p_error_jurado[::2])\n",
    "plt.ylabel('Prob. de error del jurado')\n",
    "_ = plt.xlabel('Número de jueces')\n",
    "\n",
    "# Algunas cuestiones:\n",
    "#   * ¿Cuántos jueces necesitas para estar tener una prob del 99%\n",
    "#      de que el jurado acierte con prob_error=0.3? ¿y con prob_error=0.1? \n",
    "#      ¿y con 0.45?\n",
    "#   * ¿Qué sucede si la probabilidad de equivocarse de cada juez es >0.5?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestras bootstrap y bagging\n",
    "Una muestra bootstrap estándar consiste realizar N extracciones aleatorias con reemplazamiento de una urna con N elementos. Algunas variaciones incluyen:\n",
    "\n",
    "* Realizar M extracciones con $M\\neq N$\n",
    "* Realizar las extracciones sin reemplazamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array(range(1,1201,1))\n",
    "M2 = np.array(range(1,1001,1))\n",
    "N = 1000\n",
    "\n",
    "plt.plot(M, ((N-1)/N)**M, label='M de {} con reemp.'.format(N))\n",
    "plt.plot(M2, (N-M2)/N, label='M de {} sin reemp.'.format(N))\n",
    "plt.plot([0,N],[((N-1)/N)**N,((N-1)/N)**N],'k--')\n",
    "plt.plot([N,N],[0,((N-1)/N)**N],'k--')\n",
    "plt.xlim([0,M[-1]])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('Fracción de instancias no seleccionadas')\n",
    "plt.xlabel('Número de extracciones con repetición (M)')\n",
    "_=plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class BaggingCasero:\n",
    "    def __init__(self, n_estimators=101):\n",
    "        self.n_estimators = n_estimators\n",
    "        self._estimators = []\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        N = X.shape[0]\n",
    "        for i in range(self.n_estimators):\n",
    "            \"\"\"\n",
    "              Rellenar esta parte para que cree un árbol usando\n",
    "              una muestra bootstrap de los datos\n",
    "            \"\"\"\n",
    "            self._estimators.append(tree)\n",
    "            \n",
    "    def predict(self,X):\n",
    "        votos = np.zeros((X.shape[0],len(self._estimators)))\n",
    "        # Calcula la salida de cada árbol para cada dato\n",
    "        for ie,estimator in enumerate(self._estimators):\n",
    "            votos[:,ie] = estimator.predict(X)\n",
    "            \n",
    "        \"\"\"\n",
    "           Calcula la clase más votada de cada ejemplo, es decir,\n",
    "           la moda\n",
    "        \"\"\"\n",
    "        return moda\n",
    "            \n",
    "        \n",
    "            \n",
    "bagging = BaggingCasero()\n",
    "\n",
    "bagging.fit(Xtrain, ytrain)\n",
    "\n",
    "plotModel(x1,x2,ytrain,bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\"\"\" Solo se va a implementar para regresión y para clasificación \n",
    "    binaria con clases igual a -1 y +1\n",
    "\"\"\"\n",
    "\n",
    "class SquaredErrorLoss:\n",
    "    \"\"\" Clase que define elementos para la función cuadrática de perdida \n",
    "        para regresión \"\"\"\n",
    "    \n",
    "    def F0(_, X, y):\n",
    "        \"\"\" Calcula el valor constate que minimiza la salida 'y' \"\"\"\n",
    "        pass\n",
    "\n",
    "    def residuos(_, y, F):\n",
    "        \"\"\" Calcula los residuos para un objetivo 'y' y \n",
    "            una salida del modelo F \"\"\"\n",
    "        pass\n",
    "\n",
    "    ## CAMBIO 01\n",
    "    def paso_newton_hoja(_, y, residuos, valor):\n",
    "        \"\"\" Función para actualizar la salida de una hoja el árbol\n",
    "        \n",
    "           Recibe información sobre los ejemplos de una hoja dada. En concreto\n",
    "           para los ejemplos que caen en una hoja:\n",
    "              * El vector de valores a predecir (y)\n",
    "              * Los pseudo-residuos (residuos) sobre los que se ha\n",
    "                entrenado alarbol regresor ht\n",
    "           Además recine el valor actual de salida de la hoja\n",
    "              \n",
    "            Debe devolver el valor actualizado\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, y, F):\n",
    "        \"\"\" Devuelve el valor de la función de pérdida para un objetivo 'y' y \n",
    "            una salida del modelo F \"\"\"\n",
    "        return 0.5*(y-F)**2\n",
    "    \n",
    "class LogLoss:\n",
    "    \"\"\" Clase que define elementos para la función logística de perdida \n",
    "        para clasificación de dos clases {-1, +1} \"\"\"\n",
    "    \n",
    "    def F0(_, X, y):\n",
    "        \"\"\" Calcula el valor constate que minimiza la salida 'y' \"\"\"\n",
    "        pass\n",
    "\n",
    "    def residuos(_, y, F):\n",
    "        \"\"\" Calcula los residuos para un objetivo 'y' y \n",
    "            una salida del modelo F \"\"\"\n",
    "        pass\n",
    "\n",
    "    ## CAMBIO 02\n",
    "    def paso_newton_hoja(_, y, residuos, valor):\n",
    "        \"\"\" Función para actualizar la salida de una hoja el árbol\n",
    "        \n",
    "           Recibe información sobre los ejemplos de una hoja dada. En concreto\n",
    "           para los ejemplos que caen en una hoja:\n",
    "              * El vector de valores a predecir (y)\n",
    "              * Los pseudo-residuos (residuos) sobre los que se ha\n",
    "                entrenado alarbol regresor ht\n",
    "           Además recine el valor actual de salida de la hoja\n",
    "              \n",
    "            Debe devolver el valor actualizado\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self,y, F):\n",
    "        \"\"\" Devuelve el valor de la función de pérdida para un objetivo 'y' y \n",
    "            una salida del modelo F \"\"\"\n",
    "        return np.log(1+np.exp(-2.0*y*F))\n",
    "     \n",
    "class GBCasero:\n",
    "    def __init__(self, n_estimators=101, loss=SquaredErrorLoss(), eta=0.1, depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self._estimators  = []\n",
    "        self.depth        = depth\n",
    "        self.eta          = eta\n",
    "        # La implementación de loss se usará en fit para crear el algoritmo\n",
    "        # GB de forma genérica.\n",
    "        self.loss         = loss\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "          Inicializa GB \n",
    "        \"\"\"\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth = self.depth)\n",
    "            \"\"\"\n",
    "              Rellenar esta parte para implementar GB \n",
    "              Se debe utilizar la función paso_newton de abajo\n",
    "            \"\"\"\n",
    "            self._estimators.append(tree)\n",
    "            \n",
    "    def predict(self,X):\n",
    "        \"\"\" Combinamos los valores de pesos y hs para obtener la 'salida', y:\n",
    "               * Para regresión se devuelve 'salida'\n",
    "               * Para clasificación de 2 clases se calcula la probabilidad\n",
    "                  con una sigmoidal (1 / (1 + np.exp(-2*salida))) y se \n",
    "                  devuelve la clase más probable \"\"\"\n",
    "        return result\n",
    "            \n",
    "    ## CAMBIO 03\n",
    "    def paso_newton_general(self, tree, X, y, residuos):\n",
    "        \"\"\" Esta función actualiza todas las hojas de salida\n",
    "            del árbol 'tree' utilizado la función paso_newton_hoja\n",
    "            de las clases de funcion de pérdida \"\"\"\n",
    "        TREE_LEAF = -1\n",
    "        tree = tree.tree_\n",
    "        leaf_indices = tree.apply(np.array(X,dtype=np.float32))\n",
    "        for leaf in np.where(tree.children_left == TREE_LEAF)[0]:\n",
    "            ii = leaf_indices==leaf\n",
    "            tree.value[leaf,0,0] = self.loss.paso_newton_hoja(y[ii],\n",
    "                                                              residuos[ii],\n",
    "                                                              tree.value[leaf,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CAMBIO 04: Todas las pruebas\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Basic example\n",
    "gb = GBCasero(loss=LogLoss())\n",
    "\n",
    "lb     = LabelBinarizer(pos_label = 1, neg_label = -1)\n",
    "ytrain = lb.fit_transform(ytrain).ravel()\n",
    "ytest  = lb.transform(ytest).ravel()\n",
    "\n",
    "gb.fit(Xtrain, ytrain)\n",
    "acc = np.sum(gb.predict(Xtest)==ytest)/len(ytest)\n",
    "plotModel(x1,x2,ytrain,gb,\"Acc=\"+str(acc))\n",
    "\n",
    "# Magic\n",
    "fP = 'magic04.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(dfP.values[:,:-1], dfP.values[:,-1], \n",
    "                                          test_size=0.8, random_state=1)\n",
    "lb   = LabelBinarizer(pos_label = 1, neg_label = -1)\n",
    "y_tr = lb.fit_transform(y_tr).ravel()\n",
    "y_ts = lb.transform(y_ts).ravel()\n",
    "\n",
    "gb = GBCasero(loss=LogLoss())\n",
    "\n",
    "gb.fit(X_tr, y_tr)\n",
    "print(\"Accuracy in Magic04=\",np.sum(gb.predict(X_ts)==y_ts)/len(y_ts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar el conjunto\n",
    "Se entrena un random forest con 3 árboles para visualizar la frontera de decisión cuándo se combinan en el conjunto de clasificadores y cada árbol por separado\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Ejecuta el código de con noise=0 y n_estimators=3 y estudia el resultado de los árboles por separado y en conjunto. En concreto analiza:\n",
    "<ul>\n",
    "<li> (1) Las fronteras de decisión de los árboles individuales con respecto a la frontera de los árboles combinados.</li>\n",
    "<li> (2) ¿Por qué son tan diferentes las fronteras de los árboles individuales? Para responder piensa cómo se han creado esos árboles</li>\n",
    "<li> (3) Mira los errores en test de los árboles individuales y del conjunto ¿Cuál es que mejor error obtine? ¿Por qué?</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuestas:\n",
    "    <b>Nota: No es necesario entregar ninguna de estas cuestiones</b> \n",
    "<ul>\n",
    "<li> (1) ...</li>\n",
    "<li> (2) ...</li>\n",
    "<li> (3) ...</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Ahora ejecuta las dos celdas siguientes modificando el nivel de ruiso (noise=0.0 y noise=0.3). A continuación prueba con n_estimators igual a 3, 31 y 301 para cada uno de los niveles de ruido y rellena el acierto en test y train en la siguiente tabla:<br/></div>\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">\n",
    "\n",
    "(4) Respuestas:\n",
    "\n",
    "| Acierto train/test | n_estimators=3 | n_estimators=31 | n_estimators=301 |\n",
    "|--------------------|----------------|-----------------|------------------|\n",
    "| noise=0            |                |                 |                  |\n",
    "| noise=0,3          |                |                 |                  | \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Construcción del clasificador:\n",
    "np.random.seed(11)\n",
    "clf = RandomForestClassifier(n_estimators=3) # <= Modif este valor 3, 31 y 301(antes responde a las cuestiones de arriba)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Calculo del acierto en los conjuntos de entrenamiento y test:\n",
    "score_train = clf.score(Xtrain, ytrain)\n",
    "print(\"Score train = %f\" % (score_train))\n",
    "score_test = clf.score(Xtest, ytest)\n",
    "print(\"Score test = %f\" % (score_test))\n",
    "\n",
    "scores_single_trees_test = [dt.score(Xtest, ytest) for dt in clf.estimators_[0:3]]\n",
    "\n",
    "print(\"Score test tres primeros árboles = %f,%f,%f\" % tuple(scores_single_trees_test))\n",
    "\n",
    "# Gráficas:\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "plt.subplot(231)\n",
    "t = \"Conjunto completo (acierto train = {:g})\".format(score_train)\n",
    "plotModel(x1,x2,ytrain,clf,t)\n",
    "\n",
    "plt.subplot(232)\n",
    "t = \"Conjunto completo (acierto test = {:g})\".format(score_test)\n",
    "plotModel(xbnd,ybnd,None,clf,t)\n",
    "\n",
    "# Se muestra el acierto y frontera de los 3 primeros árboles\n",
    "# del conjunto\n",
    "for i in [1,2,3]:\n",
    "    plt.subplot(2,3,3+i)\n",
    "    t = \"Arbol {}, acierto test = {:g}\".format(i,scores_single_trees_test[i-1])\n",
    "    plotModel(x1,x2,ytrain,clf.estimators_[i-1],t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">A continuación se realiza el cálculo el acierto del conjunto con en train y en test con respecto al número de clasificadores combinados. Puedes utilizar la función suministrada individualPredictions, que dado un conjunto de datos y otro de clasificadores devuelve las clasificaciones de cada clasificador base para cada ejemplo\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individualPredictions: Devuelve la predicción para cada dato por parte de cada clasificador \n",
    "#                        de un conjunto de clasificadores\n",
    "#     Entrada:\n",
    "#         - ens: lista con un conjunto de clasificadores\n",
    "#         - X  : ejemplos a clasificar\n",
    "#     Salida:\n",
    "#         - Matriz de predicciones de número de ejemplo filas y no. clasificadores columnas\n",
    "def individualPredictions(ens, X):\n",
    "    P = np.ones((X.shape[0],len(ens)))\n",
    "    it = 0\n",
    "    for dt in ens:\n",
    "        P[:,it] = dt.predict(X)\n",
    "        it += 1\n",
    "\n",
    "    return P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def accuracy(ens, pr, y):\n",
    "    pr = np.cumsum(pr,axis=1)/np.arange(1.,pr.shape[1]+1,1.)\n",
    "    pr[pr>0.5] = 1\n",
    "    pr[pr<=0.5] = 0\n",
    "\n",
    "    iclases_test = np.zeros(np.array([y]).T.shape)\n",
    "    iclases_test[y==ens.classes_[0]] = 0\n",
    "    iclases_test[y==ens.classes_[1]] = 1\n",
    "\n",
    "    Pok = pr==iclases_test\n",
    "    return np.array(Pok.sum(axis=0),dtype=float)/len(y)\n",
    "\n",
    "    \n",
    "# Cargamos datos\n",
    "fP = 'magic04.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "#separación training-test\n",
    "X_train, X_test, clases_train, clases_test = train_test_split(dfP.values[:,:-1], dfP.values[:,-1], test_size=0.8, random_state=1)\n",
    "\n",
    "n_trees = 500\n",
    "clf = RandomForestClassifier(n_estimators=n_trees)\n",
    "clf.fit(X_train, clases_train)\n",
    "\n",
    "P = individualPredictions(clf.estimators_, X_train)\n",
    "accu_tr = accuracy(clf,P,clases_train)\n",
    "\n",
    "P = individualPredictions(clf.estimators_, X_test)\n",
    "accu_ts = accuracy(clf,P,clases_test)\n",
    "\n",
    "plt.plot(range(1,n_trees+1),accu_tr,label=\"train\")\n",
    "plt.plot(range(1,n_trees+1),accu_ts,label=\"test\")\n",
    "plt.ylim([0.8,1])\n",
    "_ = plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Usando la tabla y la gráfica describe cómo evoluciona el error en en entrenemiento y test con respecto al número de árboles que se combinan en el conjunto ¿Se observa sobre ajuste al aumentar el número de clasificadores? Es decir, ¿sube el error en test a partir de algún umbral del número de clasificadores?<br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(5) Respuesta: \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting para regresión\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Tiempos de entrenamiento y test de los árboles de decisión\n",
    "Vamos a medir tiempos de entrenamiento y clasificación de árboles de decisión y a compararlos con los tiempos de las SVMs. Probaremos a entrenar los modelos con 300 datos y con 600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skpp\n",
    "import timeit\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "n_executions = 1\n",
    "\n",
    "# Cargamos datos\n",
    "fP = 'pimaND.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "# Dividimos train/test\n",
    "n_train = 300                                      # <================== Modificar 300 o 600\n",
    "perm = np.random.permutation(dfP.shape[0])\n",
    "indices_train = perm[0:n_train]\n",
    "indices_test  = perm[n_train:]\n",
    "\n",
    "    \n",
    "#clf = SVC(C=10.0, kernel='linear', degree=1.0, coef0=1.0, gamma=0.1) # <================== Modificar DT o SVM\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100)  # <================== Modificar 100 o 1000\n",
    "\n",
    "# Tiempo de entrenamiento\n",
    "tic = timeit.default_timer()\n",
    "for ie in range(n_executions):    # Puede ser necesario ejecutarlo varias veces para obtener tiempos más estables\n",
    "    clf.fit(dfP.values[indices_train,:-1],dfP.values[indices_train,-1])\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "print(\"Tiempo de entrenamiento con {} ejemplos: {:.4g} s.\".format(len(indices_train),(toc - tic)/n_executions))\n",
    "\n",
    "n_executions = 10\n",
    "\n",
    "# Tiempo de clasificacion\n",
    "tic = timeit.default_timer()\n",
    "for ie in range(n_executions):   # Puede ser necesario ejecutarlo varias veces para obtener tiempos más estables\n",
    "    _ = clf.predict(dfP.values[indices_test,:-1])\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "factor = 100.\n",
    "print(\"Tiempo de clasificar {:g} ejemplos: {:.4g} s.\".format(factor, factor*(toc - tic)/n_executions/len(indices_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Se debe ejecutar la celda de arriba utilizando conjuntos de clasificadores con 100 y 1000 árboles. Hazlo usando 300 datos de entrenamiento y 600. A continuación se debe rellenar los tiempos en la siguiente tabla comparando con lo obtenido en con árboles y SVM:<br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(6) Respuestas:\n",
    "\n",
    "|  Tiempos (s)          | Árbol  | SVM  | RF100 | RF 1000 |\n",
    "|-----------------------|--------|------|-------|---------|\n",
    "| Entrenamiento con 300 | (+)    | (+)  | (++)  | (++)    |\n",
    "| Entrenamiento con 600 | (+)    | (+)  | (++)  | (++)    |\n",
    "| Clasificación con modelo entr. con 300 (10^6 ejemplos) | (+)    | (+)  | (++)  | (++)    |\n",
    "| Clasificación con modelo entr. con 600 (10^6 ejemplos) | (+)    | (+)  | (++)  | (++)    |\n",
    "\n",
    "(+) Recuperar datos de la práctica anterior\n",
    "\n",
    "(++) Rellenar estos datos ejecutando el código de arriba\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Usando la tabla comenta los resultados.<br/>\n",
    "\n",
    "<ul>\n",
    "<li>(7) ¿Cómo varían los tiempos de entrenamiento al doblar el número de datos de entrenamiento? ¿Y los tiempos de clasificación?</li>\n",
    "<li>(8): Explica los resultados y comparalos con los de un solo árbol</li>\n",
    "</ul>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuesta:\n",
    "\n",
    "<ul>\n",
    "<li>(7): </li>\n",
    "<li>(8): </li>\n",
    "</ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Comparativa\n",
    "Vamos a comparar los resultados de clasificación de algunos conjuntos de clasificadores y árboles de decisión.\n",
    "\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Completa el código de abajo para comparar un árbol de decisión y los conjuntos bagging, adaboost y random forest. Se debe obtener el acierto para los conjuntos de datos: pimaND, spamND, magic04 y sonar. Esto se hará usando validación cruzada de 10 hojas.<br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Lista con los ficheros de datos\n",
    "dataset_names = ['pimaND.csv', 'spamND.csv', 'sonar.csv', 'magic04.csv']\n",
    "# Cargo un conjunto de datos\n",
    "idata=1\n",
    "d = pd.read_csv(dataset_names[idata], sep=',')\n",
    "print(dataset_names[idata])\n",
    "\n",
    "# Creamos las particiones en entrenamiento y test para probar los distintos modelos\n",
    "# Es importente que la partición sea igual para todos los modelos de forma que los \n",
    "# errores sean comparables. Eso se puede lograr fijando el random_state\n",
    "indexFolds = KFold(n_splits=10, shuffle=True, random_state=11)\n",
    "\n",
    "# Para conjuntos grades (pe. magic) puede que hacer entrenamiento con el 90% de los datos (como\n",
    "#   sucede con KFold usando n_folds=10) sea inviable. Si tarde damasiado puedes usar la siguiente línea\n",
    "#   para magic y tal vez para spamND\n",
    "#indexFolds = cross_validation.ShuffleSplit(*** RELLENAR AQUI EL TAMAÑO DEL CONJUNTO ***, n_iter=10, test_size=0.8, random_state=0)\n",
    "\n",
    "# Lista con los modelos a probar\n",
    "n_trees = 250\n",
    "modelos = [DecisionTreeClassifier(),\n",
    "          RandomForestClassifier(n_estimators=n_trees),\n",
    "          AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(min_samples_leaf=10), \n",
    "                             n_estimators=n_trees),\n",
    "          BaggingClassifier(n_estimators=n_trees)]\n",
    "names= ['DecisionTree', 'RandomForest', 'AdaBoost    ', 'Bagging     ']\n",
    "\n",
    "# Bucle para recorrer cada modelo a probar\n",
    "for n,clf in zip(names, modelos):\n",
    "    errors = []\n",
    "    # Recorremos las particiones\n",
    "    for idxTr, idxTs in indexFolds.split(d):\n",
    "        # Train model\n",
    "        clf.fit(d.values[idxTr,:-1],d.values[idxTr,-1])\n",
    "        # Validate model\n",
    "        score = clf.score(d.values[idxTs,:-1],d.values[idxTs,-1])\n",
    "        errors.append(1.0 - score)\n",
    "\n",
    "    errors = np.array(errors)\n",
    "    print(\"{}: {:0.3g}%%\".format(n,100*errors.mean()) + \" +- {:.3g}\".format(100*errors.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\"> Resultados:\n",
    "\n",
    "|  Error de test (%) $\\pm$ desv      | Árbol  | RandomForest  | AdaBoost | Bagging |\n",
    "|-----------------------|--------|------|-------|---------|\n",
    "| Pima  | (+)    | (+)  | (+)  | (+)    |\n",
    "| Spam  | (+)    | (+)  | (+)  | (+)    |\n",
    "| Sonar | (+)    | (+)  | (+)  | (+)    |\n",
    "| Magic | (+)    | (+)  | (+)  | (+)    |\n",
    "\n",
    "(+) Rellenar estos datos ejecutando el código implementado. Dar el error y la desviación estándar. Por ejemplo $15.0 \\pm 3.4$\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">\n",
    "Comenta los resultados:\n",
    "\n",
    "</div>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- Atributos más importantes\n",
    "Vamos a ver cuáles son los atributos más importantes de los conjuntos de datos analizados arriba. Al entrenar el conjunto se guarda en la variable feature\\_importances\\_ la importancia relativa de cada variable medida en función de cómo de alto aparece en cada árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargamos datos\n",
    "fP = 'pimaND.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "#\n",
    "#separación training-test\n",
    "X_train, X_test, clases_train, clases_test = train_test_split(dfP.values[:,:-1], dfP.values[:,-1], test_size=0.3, random_state=1)\n",
    "\n",
    "# Lista con los modelos a probar\n",
    "n_trees = 301\n",
    "clf= RandomForestClassifier(n_estimators=n_trees)\n",
    "\n",
    "# Entrenamos\n",
    "clf.fit(X_train,clases_train)\n",
    "\n",
    "# Mostramos los atributos más relevantes\n",
    "_ = plt.bar(np.arange(1,dfP.values.shape[1]), clf.feature_importances_)\n",
    "_ = plt.xticks(np.arange(1,dfP.values.shape[1])+0.5, [lab[0:3] for lab in lVarsTarg[:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\"> Indica las dos variables más importante para cada conjunto de datos:\n",
    "\n",
    "|  Error de test (%) $\\pm$ desv      | Nombre Variable 1 | Nombre Variable 2 |\n",
    "|-----------------------|--------|------|\n",
    "| Pima  | (+)    | (+)  |\n",
    "| Spam  | (+)    | (+)  |\n",
    "| Sonar | (+)    | (+)  |\n",
    "| Magic | (+)    | (+)  |\n",
    "\n",
    "(+) Rellenar estos datos \n",
    "</div>\n",
    "<br>\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">\n",
    "Comenta los resultados:\n",
    "\n",
    "</div>\n",
    "<br/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
